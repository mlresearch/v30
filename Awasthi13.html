<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Learning Using Local Membership Queries | COLT 2013 | JMLR W&amp;CP</title>

		<!-- Stylesheet -->
		<link rel="stylesheet" type="text/css" href="../css/jmlr.css">

		<!-- MathJax -->
		<script type="text/x-mathjax-config">
  			MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
		</script>
		<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>

		<!-- Metadata -->
		<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Learning Using Local Membership Queries">
<meta name="citation_author" content="Awasthi, Pranjal">
<meta name="citation_author" content="Feldman, Vitaly">
<meta name="citation_author" content="Kanade, Varun">

<meta name="citation_publication_date" content="2013">
<meta name="citation_conference_title" content="Conference on Learning Theory">
<meta name="citation_firstpage" content="398">
<meta name="citation_lastpage" content="431">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v30/Awasthi13.pdf">


    </head>
    <body>

	<div id="fixed">
<a align="right" href="http://www.jmlr.org/" target="_top"><img class="jmlr" src="../img/jmlr.jpg" align="right" border="0"></a> 
<p><br><br>
</p><p align="right"> <a href="http://www.jmlr.org/"> Home Page </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/papers"> Papers
 </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/author-info.html"> Submissions </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/news.html"> 
News </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/scope.html"> 
Scope </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/editorial-board.html"> Editorial Board </a>
 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/announcements.html"> Announcements </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/proceedings"> 
Proceedings </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/mloss">Open 
Source Software</a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/search-jmlr.html"> Search </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/manudb"> Login </a></p>

<br><br>
<p align="right"> <a href="http://jmlr.csail.mit.edu/jmlr.xml"> 
<img src="../img/RSS.gif" class="rss" alt="RSS Feed">
</a>

</p>
	</div>

	<div id="content">
		<h1>Learning Using Local Membership Queries</h1>

<div id="authors">Pranjal Awasthi, Vitaly Feldman, Varun Kanade</div>;
<div id="info">JMLR W&amp;CP 30 : 398–431, 2013</div>



<h2>Abstract</h2>
<div id="abstract">
	<p>We introduce a new model of membership query (MQ) learning, where the learning algorithm is restricted to query points that are close to random examples drawn from the underlying distribution. The learning model is intermediate between the PAC model (Valiant,1984) and the PAC+MQ model (where the queries are allowed to be arbitrary points).</p>
<p>Membership query algorithms are not popular among machine learning practitioners. Apart from the obvious difficulty of adaptively querying labellers, it has also been observed that querying unnatural points leads to increased noise from human labellers (Lang and Baum, 1992). This motivates our study of learning algorithms that make queries that are close to examples generated from the data distribution.</p>
<p>We restrict our attention to functions defined on the n-dimensional Boolean hypercube and say that a membership query is local if its Hamming distance from some example in the (random) training data is at most <span class="math">\(O(log(n))\)</span>. We show the following results in this model:</p>
<ol>
<li><p>The class of sparse polynomials (with coefficients in <span class="math">\(R\)</span>) over <span class="math">\(\{0, 1\}^n\)</span> is polynomial time learnable under a large class of locally smooth distributions using <span class="math">\(O(log(n))\)</span>-local queries. This class also includes the class of <span class="math">\(O(log(n))\)</span>-depth decision trees.</p></li>
<li><p>The class of polynomial-sized decision trees is polynomial time learnable under product distributions using <span class="math">\(O(log(n))\)</span>-local queries.</p></li>
<li><p>The class of polynomial size DNF formulas is learnable under the uniform distribution using <span class="math">\(O(log(n))\)</span>-local queries in time <span class="math">\(n^{O(log(log(n)))}\)</span>.</p></li>
<li><p>In addition we prove a number of results relating the proposed model to the traditional PAC model and the PAC+MQ model.</p></li>
</ol>
</div>

<h2>Related Material</h2>
<div id="extras">
	<ul>
		<li><a href="Awasthi13.pdf">Download PDF</a></li>
		
	</ul>
</div>

	</div>

    </body>
</html>
