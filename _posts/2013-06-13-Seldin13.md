---
pdf: http://proceedings.mlr.press/v30/Seldin13.pdf
title: 'Open Problem: Adversarial Multiarmed Bandits with Limited Advice '
abstract: 'Adversarial multiarmed bandits with expert advice is one of the fundamental
  problems in studying the exploration-exploitation trade-off. It is known that if
  we observe the advice of all experts on every round we can achieve O\left(\sqrtKT
  \ln N\right) regret, where K is the number of arms, T is the number of game rounds,
  and N is the number of experts. It is also known that if we observe the advice of
  just one expert on every round, we can achieve regret of order O\left(\sqrtNT\right).
  Our open problem is what can be achieved by asking M experts on every round, where
  1<M<N. '
section: open-problem
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Seldin13
month: 0
firstpage: 1067
lastpage: 1072
page: 1067-1072
sections: 
author:
- given: Yevgeny
  family: Seldin
- given: Koby
  family: Crammer
- given: Peter
  family: Bartlett
date: 2013-06-13
address: Princeton, NJ, USA
publisher: PMLR
container-title: Proceedings of the 26th Annual Conference on Learning Theory
volume: '30'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 6
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
