---
pdf: http://proceedings.mlr.press/v30/Kaufmann13/Kaufmann13.pdf
title: Information Complexity in Bandit Subset Selection
abstract: We consider the problem of efficiently exploring the arms of a stochastic
  bandit to identify the best subset. Under the PAC and the fixed-budget formulations,
  we derive improved bounds by using KL-divergence-based confidence intervals. Whereas
  the application of a similar idea in the regret setting has yielded bounds in terms
  of the KL-divergence between the arms, our bounds in the pure-exploration setting
  involve the Chernoff information between the arms. In addition to introducing this
  novel quantity to the bandits literature, we contribute a comparison between the
  “racing” and “smart sampling” strategies for pure-exploration problems, finding
  strong evidence in favor of the latter.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Kaufmann13
month: 0
firstpage: 228
lastpage: 251
page: 228-251
sections: 
author:
- given: Emilie
  family: Kaufmann
- given: Shivaram
  family: Kalyanakrishnan
date: 2013-06-13
address: Princeton, NJ, USA
publisher: PMLR
container-title: Proceedings of the 26th Annual Conference on Learning Theory
volume: '30'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 6
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
