---
pdf: http://proceedings.mlr.press/v30/Hutter13.pdf
title: Sparse Adaptive Dirichlet-Multinomial-like Processes
abstract: Online estimation and modelling of i.i.d. data for shortsequences over large
  or complex “alphabets” is a ubiquitous (sub)problem in machine learning, information
  theory, data compression, statistical language processing, and document analysis.
  The Dirichlet-Multinomial distribution (also called Polya urn scheme) and extensions
  thereof are widely applied for online i.i.d. estimation. Good a-priori choices for
  the parameters in this regime are difficult to obtain though. I derive an optimal
  adaptive choice for the main parameter via tight, data-dependent redundancy bounds
  for a related model. The 1-line recommendation is to set the ’total mass’ = ’precision’
  = ’concentration’ parameter to m/[2\ln\fracn+1m], where n is the (past) sample size
  and m the number of different symbols observed (so far). The resulting estimator
  is simple, online, fast,and experimental performance is superb.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Hutter13
month: 0
tex_title: Sparse Adaptive Dirichlet-Multinomial-like Processes
firstpage: 432
lastpage: 459
page: 432-459
order: 432
cycles: false
author:
- given: Marcus
  family: Hutter
date: 2013-06-13
address: Princeton, NJ, USA
publisher: PMLR
container-title: Proceedings of the 26th Annual Conference on Learning Theory
volume: '30'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 6
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
