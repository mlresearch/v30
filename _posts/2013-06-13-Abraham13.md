---
pdf: http://proceedings.mlr.press/v30/Abraham13.pdf
title: Adaptive Crowdsourcing Algorithms for the Bandit Survey Problem
abstract: Very recently crowdsourcing has become the de facto platform for distributing
  and collecting human computation for a wide range of tasks and applications such
  as information retrieval, natural language processing and machine learning. Current
  crowdsourcing platforms have some limitations in the area of quality control. Most
  of the effort to ensure good quality has to be done by the experimenter who has
  to manage the number of workers needed to reach good results.We propose a simple
  model for adaptive quality control in crowdsourced multiple-choice tasks which we
  call the “bandit survey problem”. This model is related to, but technically different
  from the well-known multi-armed bandit problem. We present several algorithms for
  this problem, and support them with analysis and simulations.Our approach is based
  in our experience conducting relevance evaluation for a large commercial search
  engine.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Abraham13
month: 0
firstpage: 882
lastpage: 910
page: 882-910
sections: 
author:
- given: Ittai
  family: Abraham
- given: Omar
  family: Alonso
- given: Vasilis
  family: Kandylas
- given: Aleksandrs
  family: Slivkins
date: 2013-06-13
address: Princeton, NJ, USA
publisher: PMLR
container-title: Proceedings of the 26th Annual Conference on Learning Theory
volume: '30'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 6
  - 13
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
