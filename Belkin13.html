<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Blind Signal Separation in the Presence of Gaussian Noise | COLT 2013 | JMLR W&amp;CP</title>

		<!-- Stylesheet -->
		<link rel="stylesheet" type="text/css" href="../css/jmlr.css">

		<!-- MathJax -->
		<script type="text/x-mathjax-config">
  			MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
		</script>
		<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>

		<!-- Metadata -->
		<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Blind Signal Separation in the Presence of Gaussian Noise">
<meta name="citation_author" content="Belkin, Mikhail">
<meta name="citation_author" content="Rademacher, Luis">
<meta name="citation_author" content="Voss, James">

<meta name="citation_publication_date" content="2013">
<meta name="citation_conference_title" content="Conference on Learning Theory">
<meta name="citation_firstpage" content="270">
<meta name="citation_lastpage" content="287">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v30/Belkin13.pdf">


    </head>
    <body>

	<div id="fixed">
<a align="right" href="http://www.jmlr.org/" target="_top"><img class="jmlr" src="../img/jmlr.jpg" align="right" border="0"></a> 
<p><br><br>
</p><p align="right"> <a href="http://www.jmlr.org/"> Home Page </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/papers"> Papers
 </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/author-info.html"> Submissions </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/news.html"> 
News </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/scope.html"> 
Scope </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/editorial-board.html"> Editorial Board </a>
 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/announcements.html"> Announcements </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/proceedings"> 
Proceedings </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/mloss">Open 
Source Software</a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/search-jmlr.html"> Search </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/manudb"> Login </a></p>

<br><br>
<p align="right"> <a href="http://jmlr.csail.mit.edu/jmlr.xml"> 
<img src="../img/RSS.gif" class="rss" alt="RSS Feed">
</a>

</p>
	</div>

	<div id="content">
		<h1>Blind Signal Separation in the Presence of Gaussian Noise</h1>

<div id="authors">Mikhail Belkin, Luis Rademacher, James Voss</div>;
<div id="info">JMLR W&amp;CP 30 : 270–287, 2013</div>



<h2>Abstract</h2>
<div id="abstract">
	A prototypical blind signal separation problem is the so-called cocktail party problem, with n people talking simultaneously and n different microphones within a room. The goal is to recover each speech signal from the microphone inputs. Mathematically this can be modeled by assuming that we are given samples from a <span class="math">\(n\)</span>-dimensional random variable <span class="math">\(X=AS\)</span>, where <span class="math">\(S\)</span> is a vector whose coordinates are independent random variables corresponding to each speaker. The objective is to recover the matrix <span class="math">\(A^{-1}\)</span> given random samples from <span class="math">\(X\)</span>. A range of techniques collectively known as Independent Component Analysis (ICA) have been proposed to address this problem in the signal processing and machine learning literature. Many of these techniques are based on using the kurtosis or other cumulants to recover the components. In this paper we propose a new algorithm for solving the blind signal separation problem in the presence of additive Gaussian noise, when we are given samples from <span class="math">\(X=AS+\eta\)</span>, where <span class="math">\(\eta\)</span> is drawn from an unknown, not necessarily spherical <span class="math">\(n\)</span>-dimensional Gaussian distribution. Our approach is based on a method for decorrelating a sample with additive Gaussian noise under the assumption that the underlying distribution is a linear transformation of a distribution with independent components. Our decorrelation routine is based on the properties of cumulant tensors and can be combined with any standard cumulant-based method for ICA to get an algorithm that is provably robust in the presence of Gaussian noise. We derive polynomial bounds for sample complexity and error propagation of our method.
</div>

<h2>Related Material</h2>
<div id="extras">
	<ul>
		<li><a href="Belkin13.pdf">Download PDF</a></li>
		
	</ul>
</div>

	</div>

    </body>
</html>
